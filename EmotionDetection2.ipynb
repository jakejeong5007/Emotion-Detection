{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmotionDetection2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakejeong5007/Emotion-Detection/blob/main/EmotionDetection2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1K_OUCXfPzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d60e45-aa66-4539-8133-48fb7683a38e"
      },
      "source": [
        "#@title Run this to download the data and setup our environment\n",
        "\n",
        "import cv2\n",
        "import dlib\n",
        "import gdown\n",
        "import pickle\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "from scipy.spatial import distance\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#Getting the csv data loaded\n",
        "dataset_url = 'https://drive.google.com/uc?id=1hNLedQCRl8uutOwtXWxBmiW3x7bckj4u'\n",
        "dataset_path = './ferdata.csv'\n",
        "gdown.download(dataset_url, dataset_path, True)\n",
        "\n",
        "###Getting the Dlib Shape predictor!\n",
        "\n",
        "dlibshape_url = 'https://drive.google.com/uc?id=1FDLHRfjs9hH1zhknOmIuebSsG6djb3yg'\n",
        "dlibshape_path ='./shape_predictor_68_face_landmarks.dat'\n",
        "gdown.download(dlibshape_url, dlibshape_path, True)\n",
        "\n",
        "###Getting the Xpure loaded\n",
        "\n",
        "pureX_url = 'https://drive.google.com/uc?id=1tc203qSeCwyayyFV7HHrNaMAdT__WoP5'\n",
        "pureX_path = './pureX.npy'\n",
        "gdown.download(pureX_url, pureX_path,True)\n",
        "\n",
        "###Getting the Xdata loaded\n",
        "\n",
        "dataX_url = 'https://drive.google.com/uc?id=1pQuzapUKRSXDNZqXuUUdJfO1L-AFuefY'\n",
        "dataX_path = './dataX.npy'\n",
        "gdown.download(dataX_url, dataX_path, True)\n",
        "\n",
        "\n",
        "###Getting the Ydata loaded\n",
        "\n",
        "dataY_url = 'https://drive.google.com/uc?id=1figaVbzcmrz8JumBs-1Ql20mbVIh_d0x'\n",
        "dataY_path = './dataY.npy'\n",
        "gdown.download(dataY_url, dataY_path, True)\n",
        "\n",
        "print (\"Data Downloaded!\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Downloaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtHdXOQqF_kA"
      },
      "source": [
        "#Milestone 1: Understanding Feature Generation Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgB5l___P_Ja"
      },
      "source": [
        "## Instructor-led Discussion: Understanding the significance of Facial landmarks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w2SA1IIrNbE"
      },
      "source": [
        "Take a look at the images with facial landmarks superimposed over the faces!\n",
        "\n",
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/0/0a/Dlib-face_landmark_detection.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLn2UT8XiF3X"
      },
      "source": [
        "###Exercise 1A(Discussion) | Est Time: | Within a student group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mQpj-xyqNJr"
      },
      "source": [
        "#### Comment on positions of Facial Landmarks(FL) based on different emotion images? Can we used euclidean distance to distinguish between emotions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqw7wKpPSCUR"
      },
      "source": [
        "##Distance between Facial Landmarks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNftU_43j2AZ"
      },
      "source": [
        "Based on our discussion, we can use the euclidean distances of all facial landmarks with each other and use it as input (X) to our model to predict our emotions (Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKiMk58TjzKc"
      },
      "source": [
        "###Exercise 1B (Discussion) | Est Time: | Within a student group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex66YDjYjuRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290be18b-44bc-4f4a-dab0-9313010ce440"
      },
      "source": [
        "#@title Q1: Number of distance values after computing euclidean distances among facial landmarks? Q2: Number of distance values after computing euclidean distances (exclusive of distances of facial landmarks points with itself)? { display-mode: \"form\" }\n",
        "\n",
        "Q1 = \"Fill Me In\" #@param [\"2304\",\"4556\",\"4624\",\"68\",\"Fill Me In\"] \n",
        "\n",
        "Q2 = \"Fill Me In\" #@param [\"2304\",\"4556\",\"4624\",\"68\",\"Fill Me In\"] \n",
        "\n",
        "if Q1 == '4624': \n",
        "  print('Yes! 68 * 68 = 4624.') \n",
        "else: \n",
        "  print('Try Again')\n",
        "\n",
        "if Q2 == \"4556\": \n",
        "  print(\"Thats Right! If we exculde the distance of points with itself, we will have 4624 - 68 = 4556 distance values\")\n",
        "else: \n",
        "  print('Try again!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Try Again\n",
            "Try again!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiQPTFiMG-Ly"
      },
      "source": [
        "###Exercise Takeaways!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNRbQK8A25Zu"
      },
      "source": [
        "Facial landmark distances can be used as features (X) into a model where the outputs (Y) are emotions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TxlMtSqDMMw"
      },
      "source": [
        "## Instructor-led Discussion: Emotion Detection Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOrucHQ3mFQv"
      },
      "source": [
        "The three main components of Emotion Detection are as follows:\n",
        "\n",
        "\n",
        "1.   Image Preprocessing\n",
        "2.   Feature Extraction\n",
        "3.   Feature Classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQgivc1AEOx8"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=13_IxWcKkliquOQXuW4-vyfbpMA3X0Xzx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTquSms-HhMX"
      },
      "source": [
        "# Milestone 2: Understand,Visualize and Prepare the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml8XwGzOVvWX"
      },
      "source": [
        "### Dataset Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPAqGjslU4T2"
      },
      "source": [
        "We will use modified version of the fer2013 dataset consisting of five emotion labels. \n",
        "\n",
        "The dataset is stored in a csvfile. Each row in the csvfile denotes an instance. \n",
        "Every instance has two column attributes : \n",
        "\n",
        "*   Pixels of the image stored in string format \n",
        "*   Integer encoding of the target label\n",
        "\n",
        "There are total of 20,000 images distributed equally across the five emotions. The images are 48\\*48 grayscale cropped images. The csvfile consists of flattened array of the image stored in form of a string\n",
        "\n",
        "The target labels are integer encoded in the csvfile.They are mapped as follows:\n",
        "\n",
        "*   0 ---> Angry\n",
        "*   1 ---> Happy\n",
        "*   2 ---> Sad\n",
        "*   3 ---> Surprise\n",
        "*   4 ---> Neutral\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbQ9sErcYPil"
      },
      "source": [
        "### Load the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLrzsniFIPn2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ac30e023-dd69-4358-a987-439e963d743c"
      },
      "source": [
        "#Integer to Label Mapping\n",
        "label_map = {0:\"ANGRY\",1:\"HAPPY\",2:\"SAD\",3:\"SURPRISE\",4:\"NEUTRAL\"}\n",
        "\n",
        "#Load the datala\n",
        "df = pd.read_csv(\"./ferdata.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>215 216 215 215 215 216 216 216 214 178 81 30 ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>244 244 244 244 243 244 242 190 132 93 81 73 7...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>255 255 255 255 255 255 255 255 255 255 255 25...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>38 56 60 52 58 65 53 44 35 48 59 60 36 30 21 3...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>77 40 27 21 22 25 20 31 27 17 27 42 47 55 51 4...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        0  215 216 215 215 215 216 216 216 214 178 81 30 ...  Training\n",
              "1        4  244 244 244 244 243 244 242 190 132 93 81 73 7...  Training\n",
              "2        4  255 255 255 255 255 255 255 255 255 255 255 25...  Training\n",
              "3        4  38 56 60 52 58 65 53 44 35 48 59 60 36 30 21 3...  Training\n",
              "4        4  77 40 27 21 22 25 20 31 27 17 27 42 47 55 51 4...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emNk3kn7-SWh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "56e0a2eb-41e6-4bba-f1da-0b8d79eb9ad4"
      },
      "source": [
        "# generate x labels for our plot\n",
        "emotion_labels = [label_map[i] for i in label_map.keys()]\n",
        "\n",
        "# generate counts for each emotion type\n",
        "emotion_counts = [np.sum(df[\"emotion\"] == i) for i in range(len(label_map))]\n",
        "\n",
        "# generate a bar plot for our emotion labels that has different colors \n",
        "[plt.bar(x = emotion_labels[i], height = emotion_counts[i] ) for i in range(len(emotion_labels))] \n",
        "\n",
        "# make the plot interpretable with x and y labels + title\n",
        "plt.xlabel('EMOTION LABEL')\n",
        "plt.ylabel('N OBSERVSATIONS')\n",
        "plt.title('A balanced distribution of emotions in our data set', y=1.05); "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UPLgR0k-fEJ"
      },
      "source": [
        "###Exercise 2A Balanced vs. Unbalanced Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG57yqywq1jW"
      },
      "source": [
        "####What would be the implications of an unbalanced dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaqNfQF5Y8iM"
      },
      "source": [
        "### Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BbN1EO_-VMc"
      },
      "source": [
        "In this section, we will convert the flattened pixel arrays to 2D images, so as to plot facial landmarks over the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25joaxHAQcw2"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baxrsFUQQeeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27aa61b4-5873-400e-c6a1-9168d88e155e"
      },
      "source": [
        "os.listdir() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'pureX.npy',\n",
              " 'dataX.npy',\n",
              " 'dataY.npy',\n",
              " 'ferdata.csv',\n",
              " 'shape_predictor_68_face_landmarks.dat',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTkynlyy75cm",
        "cellView": "form"
      },
      "source": [
        "#@title Run this code to setup the extraction of Facial Landmarks\n",
        "\n",
        "# Load's dlib's pretrained face detector model\n",
        "#frontalface_detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "\n",
        "#Load the 68 face Landmark file\n",
        "predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')\n",
        "\"\"\"\n",
        "Returns facial landmarks for the given input image path\n",
        "\"\"\"\n",
        "def get_landmarks(image):\n",
        "  \n",
        "  \n",
        "  #:type image : cv2 object\n",
        "  #:rtype landmarks : list of tuples where each tuple represents \n",
        "  #                  the x and y co-ordinates of facial keypoints\n",
        "  \n",
        "  #Bounding Box co-ordinates around the face(Training data is 48*48(cropped faces))\n",
        "  rects = [dlib.rectangle(left=1, top=1, right=47, bottom=47)]\n",
        "\n",
        "  #Read Image using OpenCV\n",
        "  #image = cv2.imread(image_path)\n",
        "  #Detect the Faces within the image\n",
        "  landmarks = [(p.x, p.y) for p in predictor(image, rects[0]).parts()]\n",
        "  return image,landmarks\n",
        "\n",
        "\"\"\"\n",
        "Display image with its Facial Landmarks\n",
        "\"\"\"\n",
        "def image_landmarks(image,face_landmarks):\n",
        "  \"\"\"\n",
        "  :type image_path : str\n",
        "  :type face_landmarks : list of tuples where each tuple represents \n",
        "                     the x and y co-ordinates of facial keypoints\n",
        "  :rtype : None\n",
        "  \"\"\"\n",
        "  radius = -2\n",
        "  circle_thickness = 1\n",
        "  image_copy = image.copy()\n",
        "  for (x, y) in face_landmarks:\n",
        "    cv2.circle(image_copy, (x, y), circle_thickness, (255,0,0), radius)\n",
        "    \n",
        "  plt.imshow(image_copy, interpolation='nearest', cmap='Greys_r')\n",
        "  plt.xticks([]); plt.yticks([])\n",
        "  plt.show()\n",
        "  \n",
        " \n",
        "'''\n",
        "Converts pixels values to 2D-image. \n",
        "Displays the image and returns the cv2 image\n",
        "object\n",
        "'''\n",
        "def pixels_image(img_pixels,plt_flag):\n",
        "  \"\"\"\n",
        "  :type image_pixels : str\n",
        "  :type plt_flag : boolean\n",
        "  :rtype image : cv2 object\n",
        "  \"\"\"\n",
        "  \n",
        "  width = 48\n",
        "  height = 48\n",
        "  \n",
        "  image = np.fromstring(img_pixels, dtype=np.uint8, sep=\" \").reshape((height, width))\n",
        "  \n",
        "  if plt_flag:\n",
        "      plt.imshow(image, interpolation='nearest', cmap=\"Greys_r\")\n",
        "      plt.xticks([]); plt.yticks([])\n",
        "      plt.show()\n",
        "      \n",
        "      \n",
        "  return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMrrq0fxlBbN"
      },
      "source": [
        "###Lets visualize our datapoints!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6kqtTORlAZ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "462592c2-5f82-4ebc-b43f-4a95a32e334a"
      },
      "source": [
        "# select random index \n",
        "i_index = np.random.randint(len(df))\n",
        "\n",
        "# extract pixel values \n",
        "image_pixels = df['pixels'][i_index]        \n",
        "\n",
        "# convert pixels to 2D Images\n",
        "image = pixels_image(image_pixels, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWq-f7B-BOjh",
        "cellView": "form"
      },
      "source": [
        "#@title Can you get the label for the face above? "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEKhOBy1-_aB"
      },
      "source": [
        "####Plot Facial Landmarks on the Datapoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLcpEqE_-w-T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "059d5f5a-eec4-4d68-aa2e-818d62db635b"
      },
      "source": [
        "# Extract the Facial Landmarks\n",
        "image, facial_landmarks = get_landmarks(image)\n",
        "# Display the Facial Landmarks on the Image\n",
        "image_landmarks(image,facial_landmarks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27HUOaMqagU7"
      },
      "source": [
        "###Extract the features and save the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh4mN71xbyvO"
      },
      "source": [
        " We'll need to create X and Y arrays for our model:\n",
        " \n",
        "      X is a list of lists, where each element in X represents a single picture\n",
        "                            where a picture is represented by a list distances \n",
        "                            between facial landmark points\n",
        "\n",
        "      Y is a list of numbers, where each element in Y represents the emotion \n",
        "                              for the corresponding picture\n",
        "\n",
        "      X_pixels is a list of lists, where each element in X represents a single \n",
        "                           picture where a picture is represented by its pixels \n",
        "\n",
        " X and Y must be ordered in the same way so that X[0] and Y[0] refer to the \n",
        " first picture, X[1] and Y[1] refer to the second picture, and so on.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiBA4Uz1ZjOb"
      },
      "source": [
        "###Euclidean Distance between Facial Landmarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZkElB0PATtd"
      },
      "source": [
        "####Exercise(Coding)\n",
        "\n",
        "Complete the function below to compute the euclidean distances between all 68 Facial Landmark points, excluding the distances of the points with themselves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AblhKSuIZufy"
      },
      "source": [
        "\"\"\"\n",
        "Computes euclidean distance between 68 Landmark Points for our features\n",
        "e_dist is a list of features that will go into our model.\n",
        "Each feature is a distance between two landmark points, and every pair of points\n",
        "must have a feature. \n",
        "Scipy Library has readily available fuction to compute euclidean distance. You can \n",
        "compute the distance using distance.euclidean(point1,point2)\n",
        "point1,point2 :2D points\n",
        "\"\"\"\n",
        "def landmarks_edist(face_landmarks):\n",
        "  \n",
        "    e_dist = []\n",
        "    # FILL ME IN!\n",
        "    # Use this to get the distance between two points: \n",
        "    #               distance.euclidean(face_landmarks[i],face_landmarks[j])\n",
        "    return e_dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im_3G3gtaqsK",
        "cellView": "form"
      },
      "source": [
        "#@title Function that preprocesses the data to extract distances between all points\n",
        "\n",
        "def preprocess_data(df):\n",
        "  \n",
        "  X = []\n",
        "  Y = []\n",
        "  X_pixels = []\n",
        "  \n",
        "  n_pixels = 2304\n",
        "  \n",
        "  for index, row in (df.iterrows()):\n",
        "\n",
        "      if index%1000 == 0:\n",
        "        print (index, \"Datapoints Processed\")\n",
        "        \n",
        "      try:\n",
        "          image = pixels_image(row['pixels'],0)\n",
        "          X_pixels.append(image.ravel()) \n",
        "          image = cv2.GaussianBlur(image,(5,5),0)\n",
        "         \n",
        "          _,face_landmarks = get_landmarks(image)\n",
        "          X.append(landmarks_edist(face_landmarks)) # Using our feature function!\n",
        "          Y.append(row['emotion'])\n",
        "\n",
        "      except Exception as e:\n",
        "          print (\"An error occured:\",e)\n",
        "\n",
        "  #Save the data \n",
        "  np.save(\"pureX\", X_pixels)\n",
        "  np.save(\"dataX\", X)\n",
        "  np.save(\"dataY\", Y)\n",
        "  \n",
        "  return np.array(X_pixels),np.array(X),np.array(Y) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tMU3NCZcpcF"
      },
      "source": [
        "###Load the Saved Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cypubed0HIBt"
      },
      "source": [
        "# set to True if we want to preload data -- which has already been generated for us :) \n",
        "preload = True \n",
        "\n",
        "if preload: \n",
        "\n",
        "  # load outputs saved in this folder after running preprocess_data() \n",
        "  dataX = np.load('./dataX.npy')\n",
        "  dataY = np.load('./dataY.npy')\n",
        "  \n",
        "else: \n",
        "  \n",
        "  # this takes 15-20 minutes to run, but someone has already run it and saved the ouputs in this folder\n",
        "  pureX, dataX, dataY = preprocess_data(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "243exuhMd38d"
      },
      "source": [
        "###Split the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNWZEOrJDVpF"
      },
      "source": [
        "We split our data into different 'sets' that each will work differently with our machine learning model.\n",
        "\n",
        "Think of our AI as a machine learning 'student'.\n",
        "\n",
        "**Training Set**: Our training set is like a training manual. Our algorithm will read, or 'train', on this over and over again to try and learn its task.\n",
        "\n",
        "**Test Set**: Our test set is like a test. It is testing our model on problems that it has not seen before.\n",
        "\n",
        "We usually have a much larger training manual than our test. Let's see if this is the case with our data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cAC2tMjwK34"
      },
      "source": [
        "#Split Data into Train, Test (90-10)\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.1, random_state=42,stratify =dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFES356Ndp6U"
      },
      "source": [
        "### Instructor-led Discussion: Standardization of Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbtM9MnxBozT"
      },
      "source": [
        "Standardization is the process of putting different variables on the same scale. It is a transformation that centers the data by removing the mean value of each feature and then scale it by dividing (non-constant) features by their standard deviation.\n",
        "\n",
        "After standardizing data the mean will be zero and the standard deviation one.\n",
        "\n",
        "We can use sklearn's inbuilt function which will help us to standardize our train data:\n",
        "* `StandardScaler()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctD2nHn1wKFA"
      },
      "source": [
        "####Standardize the data####################\n",
        "###Note: Do not use test data to fit your Standardscaler Model\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgzUfFcdPIkr"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7GpTLtCUd9c"
      },
      "source": [
        "### Instructor-led Discussion: Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZLbw8c1VRik"
      },
      "source": [
        "Dimensionality reduction helps us find a low-dimensional representation of the data that retains as much information as possible.\n",
        "\n",
        "Principal Component Analysis (PCA) is one such technique.PCA is a technique used to emphasize variation and bring out strong patterns in a dataset. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVKY8f_V5_1C"
      },
      "source": [
        "#Reduces features by maintaining 95% variance of the data\n",
        "#After doing PCA on our training data, 4556 Dimensions --->reduced to 20\n",
        "#Note: PCA is trained only on training data \n",
        "pca = PCA(.95)\n",
        "pca.fit(X_train)\n",
        "\n",
        "X_train = pca.transform(X_train)\n",
        "X_test= pca.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3fh0Q8CPGeJ"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV0jORxMH3w1"
      },
      "source": [
        "#Milestone 3 : Applying Machine Learning to Emotion Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx3TiV9KJSSl"
      },
      "source": [
        "##Activity 3a. Defining our machine learning problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRmAsd_WJX7C"
      },
      "source": [
        "Before we build our model, we have to identify what kind of problem it will solve and what data it's going to use. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNxpdkT_JZF3"
      },
      "source": [
        "### Instructor-led Discussion: Machine Learning for Emotion Detection?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6PKSHcpJisw"
      },
      "source": [
        "What WILL our model look like? Remember, in machine learning, we always identify inputs and outputs. Our goal is to predict outputs from inputs with either classification or regression.\n",
        "\n",
        "In classification, our output is a category (like dogs or cats).\n",
        "\n",
        "In regression, our output is a value (like 0, 0.1, 0.3, 100, ...)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "049tc1P6JslF"
      },
      "source": [
        "#@title How will our model operate? { display-mode: \"form\" }\n",
        "\n",
        "#@markdown What are our inputs? \n",
        "inputs = \"Fill Me In\" #@param [\"images\", \"facial landmarks\", \"distances between facial landmarks\", \"Fill Me In\"]\n",
        "\n",
        "#@markdown What are our outputs? \n",
        "outputs = \"Fill Me In\" #@param [\"integer encoded emotions\", \"images\", \"image edges\", \"Fill Me In\"]\n",
        "\n",
        "#@markdown What kind of problem will our AI model solve? \n",
        "problem_type  = \"Fill Me In\" #@param [\"classification\", \"regression\",\"Fill Me In\"]\n",
        "\n",
        "\n",
        "if inputs == \"distances between facial landmarks\":\n",
        "  print(\"Yes, our inputs are our distance between facial landmarks!\")\n",
        "else:\n",
        "  print('Not quite our inputs.')\n",
        "\n",
        "if outputs == \"integer encoded emotions\":\n",
        "  print(\"Yes, our outputs are integer encoded emotions!\")\n",
        "else:\n",
        "  print('Not quite our outputs.')\n",
        "  \n",
        "if problem_type == \"classification\":\n",
        "  print(\"We are trying to predict labels, therefore this is classification!\")\n",
        "else:\n",
        "  print('Not quite our problem!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZGgfUZNJyTF"
      },
      "source": [
        "## Activity 3b. Building and evaluating models\n",
        "\n",
        "\n",
        "We've tried a the KNN, Logistic Regression,Decision Tree model last week in sklearn. Establish best baseline acccuracy using either of the models today. Below, we list it with the sample parameters:\n",
        "* `knn = KNeighborsClassifier(n_neighbors = 1)`\n",
        "* `lr = LogisticRegression(solver='lbfgs',multi_class='multinomial')`\n",
        "* `dt = DecisionTreeClassifier(max_depth=1)`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Test your models with accuracy_score on the test_data, which can be accessed through the X_test variable\n",
        "\n",
        "Try to build the best model that you can! \n",
        "\n",
        "Human accuracy for the fer2013 dataset is 65% +- 5%. Lets try getting as closer as possible!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqavAnDpKDqE"
      },
      "source": [
        "### Exercise (Coding)     | Est Time | Within a student group\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOiec1fe4G0t"
      },
      "source": [
        "###Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pCwBkhyKAju"
      },
      "source": [
        "### YOUR CODE BELOW\n",
        "### USE AS MANY CELLS AS YOU WANT!\n",
        "### NAME YOUR MODEL as knn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paaaxQ3lkmcV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnoF1kjw3wZ1"
      },
      "source": [
        "###Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f8MO1W1sYYV"
      },
      "source": [
        "### YOUR CODE BELOW\n",
        "### USE AS MANY CELLS AS YOU WANT!\n",
        "### PREDICT TEST LABELS AND SAVE THEM AS y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJVpZmRSN2lY"
      },
      "source": [
        "###Exercise 3A(Discussion) | Est Time: | Within a student group\n",
        "\n",
        "Discussion over different algorithms used for Emotion Detection!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVr-933j4LRC"
      },
      "source": [
        "###Plot the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN0uVF7cwbGk"
      },
      "source": [
        "'''\n",
        "Plots the confusion Matrix and saves it\n",
        "Pass the true labels and the predicted labels\n",
        "'''\n",
        "def plot_confusion_matrix(y_true,y_predicted):\n",
        "  cm = metrics.confusion_matrix(y_true, y_predicted)\n",
        "  print (\"Plotting the Confusion Matrix\")\n",
        "  labels = list(label_map.values())\n",
        "  df_cm = pd.DataFrame(cm,index = labels,columns = labels)\n",
        "  fig = plt.figure()\n",
        "  res = sns.heatmap(df_cm, annot=True,cmap='Blues', fmt='g')\n",
        "  plt.yticks([0.5,1.5,2.5,3.5,4.5], labels,va='center')\n",
        "  plt.title('Confusion Matrix - TestData')\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  #plt.savefig(fig_name)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7BrfLuF7Q4X"
      },
      "source": [
        "plot_confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iyM_SREPTbE"
      },
      "source": [
        "####Exercise (Discussion) | Est Time: | Within a student group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVsJs_arPTnR",
        "cellView": "form"
      },
      "source": [
        "#@title Take a look at your confusion Matrix and answer the following questions\n",
        "\n",
        "#@markdown Name most correctly classified emotion? \n",
        "correct_emotion = \"Fill Me In\"#@param [\"Anger\",\"Happy\",\"Sad\",\"Surprise\",\"Fill Me In\"] \n",
        "\n",
        "#@markdown Name most incorrectly classified emotion? \n",
        "incorrect_emotion = \"Fill Me In\"#@param [\"Anger\",\"Happy\",\"Sad\",\"Surprise\",\"Fill Me In\"] \n",
        "\n",
        "#@markdown Sad Emotion is highly misclassified as?\n",
        "sad_misclassify =\"Fill Me In\"#@param [\"Anger\",\"Happy\",\"Sad\",\"Surprise\",\"Fill Me In\"] \n",
        "\n",
        "#@markdown Neutral Emotion is highly misclassified as?\n",
        "neutral_misclassify =\"Fill Me In\"#@param [\"Anger\",\"Happy\",\"Sad\",\"Surprise\",\"Fill Me In\"] \n",
        "\n",
        "\n",
        "#@markdown Angry Emotion is highly misclassified as?\n",
        "angry_misclassify =\"Fill Me In\"#@param [\"Anger\",\"Happy\",\"Sad\",\"Surprise\",\"Fill Me In\"] \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0dNBYIPI2-c"
      },
      "source": [
        "#Milestone 4: Coding Exercise\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GolaaB1-tvBC"
      },
      "source": [
        "We performed feature generation and extraction process in the previous sections. Now train your best model from Section 3 again with actual pixels of the images with standardization.\n",
        "\n",
        "####Report and Comment over the result!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqMKoYD0Ib9L"
      },
      "source": [
        "#Load the true pixel data and corresponding labels\n",
        "X = np.load('pureX.npy')\n",
        "Y = np.load('dataY.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WatuJy48Qe__"
      },
      "source": [
        "###YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTI1-quUzf96"
      },
      "source": [
        "#Finish!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh00iNeFgUQJ"
      },
      "source": [
        "### Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfM0GGKm1FMQ"
      },
      "source": [
        "# extract images as vectors, convert from strings to ints -- this is called a \"list comprihension\" \n",
        "x_image = np.array( [np.fromstring(df['pixels'][i], dtype=np.uint8, sep=\" \") for i in range(len(df))] ) \n",
        "\n",
        "# extract labels in the same way--through a list comprehension\n",
        "y_image = np.array( [df['emotion'][i] for i in range(len(df)) ])\n",
        "\n",
        "# generate train-test (90/10) splits\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_image, y_image, test_size=0.1,random_state=42)\n",
        "\n",
        "# define the model\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "\n",
        "# train \n",
        "print (\"training knn model ...\")\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# test\n",
        "print (\"Predict for KNN Model\")\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# display results\n",
        "print (\"KNN Test Accuracy on raw image inputs:\", metrics.accuracy_score(y_test, y_pred_knn))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}